{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet transformers\n!pip install --quiet pytorch-lightning\n!pip install --quiet tokenizers\n!pip install --quiet SentencePiece ","metadata":{"execution":{"iopub.status.busy":"2022-12-04T17:12:59.445299Z","iopub.execute_input":"2022-12-04T17:12:59.446232Z","iopub.status.idle":"2022-12-04T17:13:49.660961Z","shell.execute_reply.started":"2022-12-04T17:12:59.446082Z","shell.execute_reply":"2022-12-04T17:13:49.659492Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom sklearn.model_selection import train_test_split\nfrom termcolor import colored\nimport textwrap\n\nfrom transformers import(\n    AdamW,\n    T5ForConditionalGeneration,\n    T5Tokenizer\n)\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-12-04T17:13:49.663693Z","iopub.execute_input":"2022-12-04T17:13:49.664095Z","iopub.status.idle":"2022-12-04T17:14:02.651261Z","shell.execute_reply.started":"2022-12-04T17:13:49.664042Z","shell.execute_reply":"2022-12-04T17:14:02.649635Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class ParaphraseModel(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.model =  T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict= True)\n    \n    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels= None):\n        \n        output = self.model(\n            input_ids,\n            attention_mask = attention_mask,\n            labels = labels,\n            decoder_attention_mask = decoder_attention_mask\n        )\n        \n        return output.loss, output.logits\n    \n    def training_step(self, batch, batch_idx):\n        input_ids = batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels = batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            decoder_attention_mask = labels_attention_mask,\n            labels = labels\n        )\n        \n        self.log(\"train_loss\", loss, prog_bar= True, logger= True)\n        return loss\n        \n        \n    def validation_step(self, batch, batch_idx):\n        input_ids = batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels = batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            decoder_attention_mask = labels_attention_mask,\n            labels = labels\n        )\n        \n        self.log(\"val_loss\", loss, prog_bar= True, logger= True)\n        return loss\n        \n    def test_step(self, batch, batch_idx):\n        input_ids = batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels = batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            decoder_attention_mask = labels_attention_mask,\n            labels = labels\n        )\n        \n        self.log(\"test_loss\", loss, prog_bar= True, logger= True)\n        return loss\n    \n    \n    def configure_optimizers(self):\n        return AdamW(self.parameters(), lr = 0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T17:14:02.654207Z","iopub.execute_input":"2022-12-04T17:14:02.655753Z","iopub.status.idle":"2022-12-04T17:14:02.675995Z","shell.execute_reply.started":"2022-12-04T17:14:02.655692Z","shell.execute_reply":"2022-12-04T17:14:02.674541Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = \"google/mt5-small\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n\ntrained_model = ParaphraseModel.load_from_checkpoint(\n    \"../input/finetune-mt5/checkpoint-checkpoints.ckpt\"\n)\ntrained_model.freeze()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-04T17:14:02.679694Z","iopub.execute_input":"2022-12-04T17:14:02.680322Z","iopub.status.idle":"2022-12-04T17:15:36.014110Z","shell.execute_reply.started":"2022-12-04T17:14:02.680262Z","shell.execute_reply":"2022-12-04T17:15:36.012533Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd7d3807cb6470f82216d47dd1ff4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2199ffa8964e54a4735de9c897e330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/82.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34c183954f2e4f82934fc3f12c34c988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/553 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe11f3d2d7bf4d9589ca5b9e8e6f7429"}},"metadata":{}},{"name":"stderr","text":"You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f2eae2c8a6422fbe7a22c6c133bf4b"}},"metadata":{}}]},{"cell_type":"code","source":"def paraphraser(text):\n  text_encoding = tokenizer(\n      text,\n      max_length= 90,\n      padding= True,\n      return_attention_mask= True,\n      add_special_tokens= True,\n      return_tensors= \"pt\"\n  )\n\n  generated_ids = trained_model.model.generate(\n      input_ids= text_encoding[\"input_ids\"],\n      attention_mask= text_encoding[\"attention_mask\"],\n      max_length= 512,\n      num_beams= 2,\n      early_stopping= True\n  )\n\n  preds =  [\n      tokenizer.decode(gen_id, skip_special_tokens= True, clean_up_tokenization_spaces= True)\n      for gen_id in generated_ids\n      ]\n  return \"\".join(preds)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T17:15:36.016395Z","iopub.execute_input":"2022-12-04T17:15:36.016970Z","iopub.status.idle":"2022-12-04T17:15:36.026530Z","shell.execute_reply.started":"2022-12-04T17:15:36.016909Z","shell.execute_reply":"2022-12-04T17:15:36.025127Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"> ***Please press Run all at the top of the page and then enter your sentence in the red \"\" in the box below.***","metadata":{}},{"cell_type":"code","source":"paraphraser(\"حتمالا شما مادر بسیار سلطه پذیری داشتید.\")\n","metadata":{"execution":{"iopub.status.busy":"2022-12-04T17:23:24.066121Z","iopub.execute_input":"2022-12-04T17:23:24.066743Z","iopub.status.idle":"2022-12-04T17:23:25.579071Z","shell.execute_reply.started":"2022-12-04T17:23:24.066703Z","shell.execute_reply":"2022-12-04T17:23:25.577785Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'شما باید مادر بسیار سلطه پذیری داشته باشید'"},"metadata":{}}]}]}