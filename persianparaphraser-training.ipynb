{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet transformers\n!pip install --quiet pytorch-lightning\n!pip install --quiet tokenizers\n!pip install --quiet SentencePiece ","metadata":{"id":"WyIaCSYqy4Hk","outputId":"ca759c0f-00af-4dec-9737-773bb0e3fa7f","execution":{"iopub.status.busy":"2022-10-22T08:10:46.355026Z","iopub.execute_input":"2022-10-22T08:10:46.355646Z","iopub.status.idle":"2022-10-22T08:11:32.431409Z","shell.execute_reply.started":"2022-10-22T08:10:46.355556Z","shell.execute_reply":"2022-10-22T08:11:32.430080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom sklearn.model_selection import train_test_split\nfrom termcolor import colored\nimport textwrap\n\nfrom transformers import(\n    AdamW,\n    T5ForConditionalGeneration,\n    T5Tokenizer\n)\nfrom tqdm.auto import tqdm","metadata":{"id":"oftgrWPPy4Hk","execution":{"iopub.status.busy":"2022-10-22T08:11:37.482907Z","iopub.execute_input":"2022-10-22T08:11:37.483732Z","iopub.status.idle":"2022-10-22T08:11:47.027070Z","shell.execute_reply.started":"2022-10-22T08:11:37.483689Z","shell.execute_reply":"2022-10-22T08:11:47.025849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.seed_everything(20)","metadata":{"id":"MQ3zKZu1y4Hl","outputId":"271b4df0-3063-499b-e2a4-eaaf7ef0bd05","execution":{"iopub.status.busy":"2022-10-22T08:11:53.067357Z","iopub.execute_input":"2022-10-22T08:11:53.068074Z","iopub.status.idle":"2022-10-22T08:11:53.080362Z","shell.execute_reply.started":"2022-10-22T08:11:53.068035Z","shell.execute_reply":"2022-10-22T08:11:53.079319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/persian-paraphrase-dataset/Chunk_4_official.csv\")","metadata":{"id":"kpu6Luohy4Hl","execution":{"iopub.status.busy":"2022-10-22T08:12:17.872222Z","iopub.execute_input":"2022-10-22T08:12:17.873176Z","iopub.status.idle":"2022-10-22T08:12:21.630030Z","shell.execute_reply.started":"2022-10-22T08:12:17.873136Z","shell.execute_reply":"2022-10-22T08:12:21.628923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"Hb8-IA-Bt84X","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.rename(columns= {\"input_text\": \"question\", \"target_text\": \"answer\"})\n","metadata":{"id":"Y5OFO5IFy4Hl","execution":{"iopub.status.busy":"2022-10-22T15:43:03.281831Z","iopub.execute_input":"2022-10-22T15:43:03.282415Z","iopub.status.idle":"2022-10-22T15:43:03.383653Z","shell.execute_reply.started":"2022-10-22T15:43:03.282360Z","shell.execute_reply":"2022-10-22T15:43:03.380521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size= 0.2)\n\nlen(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:50:47.961756Z","iopub.execute_input":"2022-07-24T05:50:47.962363Z","iopub.status.idle":"2022-07-24T05:50:48.128123Z","shell.execute_reply.started":"2022-07-24T05:50:47.962327Z","shell.execute_reply":"2022-07-24T05:50:48.127201Z"},"id":"wxf-WAJEy4Hm","outputId":"9707734e-ab4a-47e3-f2ce-5fced043ce85","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"ZWY_RrK7y4Hm"}},{"cell_type":"code","source":"class ParaphraseDataset(Dataset):\n    def __init__(\n        self,\n        data: pd.DataFrame,\n        tokenizer: T5Tokenizer.from_pretrained(\"google/mt5-small\"),\n        text_max_token_len: int = 512,\n        paraphrase_max_token_len: int = 512\n        \n        ):\n        \n        self.data = data\n        self.tokenizer = tokenizer\n        self.text_max_token_len = text_max_token_len\n        self.paraphrase_max_token_len = paraphrase_max_token_len\n        \n    \n    def __len__(self):\n        return len(self.data)\n        \n    def __getitem__(self, index: int):\n            \n        data_row = self.data.iloc[index]\n            \n        text = data_row[\"question\"]\n            \n        text_encoding = tokenizer(\n            text,\n            max_length= self.text_max_token_len,\n            padding= \"max_length\",\n            truncation= True,\n            return_attention_mask= True,\n            add_special_tokens= True,\n            return_tensors= \"pt\"\n        )\n            \n        paraphrase_encoding = tokenizer(\n            data_row[\"answer\"],\n            max_length= self.paraphrase_max_token_len,\n            padding= \"max_length\",\n            truncation= True,\n            return_attention_mask= True,\n            add_special_tokens= True,\n            return_tensors= \"pt\"\n        )\n            \n        labels = paraphrase_encoding[\"input_ids\"]\n        labels[labels == 0] = -100\n            \n        return dict(\n            text = text,\n            paraphrase = data_row[\"answer\"],\n            text_input_ids = text_encoding[\"input_ids\"].flatten(),\n            text_attention_mask = text_encoding[\"attention_mask\"].flatten(),\n            labels = labels.flatten(),\n            labels_attention_mask = paraphrase_encoding[\"attention_mask\"].flatten()\n            )","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:50:51.986936Z","iopub.execute_input":"2022-07-24T05:50:51.987840Z","iopub.status.idle":"2022-07-24T05:51:03.193523Z","shell.execute_reply.started":"2022-07-24T05:50:51.987794Z","shell.execute_reply":"2022-07-24T05:51:03.192529Z"},"id":"iruk4Impy4Hn","outputId":"3f93333f-652c-457b-bc06-a53b0d364485","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ParaphraseDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        train_df: pd.DataFrame,\n        test_df: pd.DataFrame,\n        tokenizer: T5Tokenizer,\n        batch_size: int = 8,\n        text_max_token_len: int = 512,\n        paraphrase_max_token_len: int = 128\n    ):\n        \n        super().__init__()\n        \n        self.train_df = train_df\n        self.test_df = test_df\n        \n        self.batch_size = batch_size\n        self.tokenizer = tokenizer\n        self.text_max_token_len = text_max_token_len\n        self.paraphrase_max_token_len = paraphrase_max_token_len\n        \n    def setup(self, stage= None):\n        self.train_dataset = ParaphraseDataset(\n            self.train_df,\n            self.tokenizer,\n            self.text_max_token_len,\n            self.paraphrase_max_token_len\n        )\n        \n        self.test_dataset = ParaphraseDataset(\n            self.test_df,\n            self.tokenizer,\n            self.text_max_token_len,\n            self.paraphrase_max_token_len\n        )\n    \n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size = self.batch_size,\n            shuffle = True,\n            num_workers = 2\n        )\n    \n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size = self.batch_size,\n            shuffle = False,\n            num_workers = 2  \n        )\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size = self.batch_size,\n            shuffle = False,\n            num_woekers = 2\n        )\n        \n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:07.483206Z","iopub.execute_input":"2022-07-24T05:51:07.483913Z","iopub.status.idle":"2022-07-24T05:51:07.504127Z","shell.execute_reply.started":"2022-07-24T05:51:07.483866Z","shell.execute_reply":"2022-07-24T05:51:07.502704Z"},"id":"NI8pQ0VCy4Ho","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = \"google/mt5-small\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:10.786966Z","iopub.execute_input":"2022-07-24T05:51:10.787356Z","iopub.status.idle":"2022-07-24T05:51:16.244489Z","shell.execute_reply.started":"2022-07-24T05:51:10.787324Z","shell.execute_reply":"2022-07-24T05:51:16.243473Z"},"id":"J10jRoVHy4Hp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_token_counts, paraphrase_token_counts = [], []\n\ntrain_df\nfor _, row in train_df.iterrows():\n    text_token_count = len(tokenizer.encode(row[\"question\"]))\n    text_token_counts.append(text_token_count)\n    \n    paraphrase_token_count = len(tokenizer.encode(row[\"answer\"]))\n    paraphrase_token_counts.append(paraphrase_token_count)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:18.298005Z","iopub.execute_input":"2022-07-24T05:51:18.298391Z","iopub.status.idle":"2022-07-24T05:51:19.231482Z","shell.execute_reply.started":"2022-07-24T05:51:18.298359Z","shell.execute_reply":"2022-07-24T05:51:19.230530Z"},"id":"IzoB_K2Gy4Hp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(text_token_counts), max(paraphrase_token_counts)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:22.085974Z","iopub.execute_input":"2022-07-24T05:51:22.086371Z","iopub.status.idle":"2022-07-24T05:51:22.096061Z","shell.execute_reply.started":"2022-07-24T05:51:22.086339Z","shell.execute_reply":"2022-07-24T05:51:22.094770Z"},"id":"lPX1sGGiy4Hp","outputId":"733f3f63-7bb4-44b7-a58f-afd29da6b260","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2)\n\nsns.histplot(text_token_counts, ax= ax1)\nax1.set_title(\"Question token counts\")\n\nsns.histplot(paraphrase_token_counts, ax= ax2)\nax2.set_title(\"Answer token counts\")","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:24.720148Z","iopub.execute_input":"2022-07-24T05:51:24.720872Z","iopub.status.idle":"2022-07-24T05:51:25.115124Z","shell.execute_reply.started":"2022-07-24T05:51:24.720835Z","shell.execute_reply":"2022-07-24T05:51:25.114171Z"},"id":"6vUMuJLhy4Hq","outputId":"8d7d28d5-a9ef-43d1-f92b-55ac96991882","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 3\nBATCH_SIZE = 8 \n\ndata_module = ParaphraseDataModule(train_df, test_df, tokenizer, batch_size= BATCH_SIZE) \n","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:31.418178Z","iopub.execute_input":"2022-07-24T05:51:31.418892Z","iopub.status.idle":"2022-07-24T05:51:31.424583Z","shell.execute_reply.started":"2022-07-24T05:51:31.418854Z","shell.execute_reply":"2022-07-24T05:51:31.423510Z"},"id":"bEla2nDwy4Hq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"2qgOkzJWy4Hq"}},{"cell_type":"code","source":"class ParaphraseModel(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        self.model =  T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict= True)\n    \n    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels= None):\n        \n        output = self.model(\n            input_ids,\n            attention_mask = attention_mask,\n            labels = labels,\n            decoder_attention_mask = decoder_attention_mask\n        )\n        \n        return output.loss, output.logits\n    \n    def training_step(self, batch, batch_idx):\n        input_ids = batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels = batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            decoder_attention_mask = labels_attention_mask,\n            labels = labels\n        )\n        \n        self.log(\"train_loss\", loss, prog_bar= True, logger= True)\n        return loss\n        \n        \n    def validation_step(self, batch, batch_idx):\n        input_ids = batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels = batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            decoder_attention_mask = labels_attention_mask,\n            labels = labels\n        )\n        \n        self.log(\"val_loss\", loss, prog_bar= True, logger= True)\n        return loss\n        \n    def test_step(self, batch, batch_idx):\n        input_ids = batch[\"text_input_ids\"]\n        attention_mask = batch[\"text_attention_mask\"]\n        labels = batch[\"labels\"]\n        labels_attention_mask = batch[\"labels_attention_mask\"]\n        \n        loss, outputs = self(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            decoder_attention_mask = labels_attention_mask,\n            labels = labels\n        )\n        \n        self.log(\"test_loss\", loss, prog_bar= True, logger= True)\n        return loss\n    \n    \n    def configure_optimizers(self):\n        return AdamW(self.parameters(), lr = 0.0001)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:34.736298Z","iopub.execute_input":"2022-07-24T05:51:34.736905Z","iopub.status.idle":"2022-07-24T05:51:34.758819Z","shell.execute_reply.started":"2022-07-24T05:51:34.736861Z","shell.execute_reply":"2022-07-24T05:51:34.757747Z"},"id":"S78jWa_2y4Hq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ParaphraseModel()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:51:38.879503Z","iopub.execute_input":"2022-07-24T05:51:38.880056Z","iopub.status.idle":"2022-07-24T05:52:35.903551Z","shell.execute_reply.started":"2022-07-24T05:51:38.880021Z","shell.execute_reply":"2022-07-24T05:52:35.902559Z"},"id":"atK3EGXvy4Hr","outputId":"23ce0719-7b36-4aff-9660-b939a1e82f71","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir ./lightning_logs\n","metadata":{"execution":{"iopub.status.busy":"2022-07-24T05:55:33.523999Z","iopub.execute_input":"2022-07-24T05:55:33.524379Z","iopub.status.idle":"2022-07-24T05:55:33.538949Z","shell.execute_reply.started":"2022-07-24T05:55:33.524348Z","shell.execute_reply":"2022-07-24T05:55:33.537692Z"},"id":"X_xnqPwAy4Hr","outputId":"bfb3e923-5dee-4c9f-a2ea-f7751c2779bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n    dirpath   = \"checkpoint\",\n    filename   = \"best-checkpoint\",\n    save_top_k = 1,\n    monitor    = \"val_loss\",\n    mode       = \"min\"\n)\n\nlogger = TensorBoardLogger(\"lightning_logs\", name= \"Paraphraser\")\n\n\ntrainer =  pl.Trainer(\n    logger                    = logger,\n    enable_checkpointing      = checkpoint_callback,\n    max_epochs                = N_EPOCHS,\n    gpus                      = 2,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-23T06:27:32.554049Z","iopub.execute_input":"2022-07-23T06:27:32.554696Z","iopub.status.idle":"2022-07-23T06:27:32.564919Z","shell.execute_reply.started":"2022-07-23T06:27:32.554660Z","shell.execute_reply":"2022-07-23T06:27:32.563883Z"},"id":"nqtZRUday4Hr","outputId":"a71e82c5-239b-4386-c2ea-6fe293d84d1b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2022-07-23T06:50:11.772840Z","iopub.execute_input":"2022-07-23T06:50:11.773198Z","iopub.status.idle":"2022-07-23T06:51:07.448661Z","shell.execute_reply.started":"2022-07-23T06:50:11.773155Z","shell.execute_reply":"2022-07-23T06:51:07.447304Z"},"id":"a3G3QCUcy4Hr","outputId":"bafcac9b-96de-495d-d9dd-1b7d233cc268","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{"id":"GnAx1GgjF3WC"}},{"cell_type":"code","source":"MODEL_NAME = \"google/mt5-small\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n\ntrained_model = ParaphraseModel.load_from_checkpoint(\n    trainer.checkpoint_callback.best_model_path\n)\ntrained_model.freeze()","metadata":{"id":"l3HQFJTlFja4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def paraphraser(text):\n  text_encoding = tokenizer(\n      text,\n      max_length= 90,\n      padding= True,\n      return_attention_mask= True,\n      add_special_tokens= True,\n      return_tensors= \"pt\"\n  )\n\n  generated_ids = trained_model.model.generate(\n      input_ids= text_encoding[\"input_ids\"],\n      attention_mask= text_encoding[\"attention_mask\"],\n      max_length= 512,\n      num_beams= 2,\n      reopetition_penalty= 2.5,\n      lenght_penalty= 1.0,\n      early_stopping= True\n  )\n\n  preds =  [\n      tokenizer.decode(gen_id, skip_special_tokens= True, clean_up_tokenization_spaces= True)\n      for gen_id in generated_ids\n      ]\n\n  return \"\".join(preds)","metadata":{"id":"iBMq4oglGtI3"},"execution_count":null,"outputs":[]}]}